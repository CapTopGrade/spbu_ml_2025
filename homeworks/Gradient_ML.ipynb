{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd68e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Для сравнения может потребоваться sklearn, если разрешен для этой цели\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Вспомогательный класс: Простое дерево регрессии (упрощенная версия)\n",
    "class SimpleRegressionTree:\n",
    "    \"\"\"\n",
    "    Очень простое дерево регрессии.\n",
    "    Разделяет данные один раз по лучшему признаку и порогу,\n",
    "    предсказывает среднее значение целевой переменной в каждом листе.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth=1):\n",
    "        \"\"\"\n",
    "        Инициализация дерева.\n",
    "\n",
    "        Args:\n",
    "            max_depth (int): Максимальная глубина дерева. Для простого дерева регрессии\n",
    "                             в GB обычно используют маленькую глубину (например, 1 или 3).\n",
    "                             По умолчанию 1 (решающий пень).\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.left_value = None  # Предсказанное значение в левом листе\n",
    "        self.right_value = None # Предсказанное значение в правом листе\n",
    "        self.left_tree = None   # Левое поддерево (для max_depth > 1)\n",
    "        self.right_tree = None  # Правое поддерево (для max_depth > 1)\n",
    "        self.is_leaf = True     # Флаг, является ли узел листом\n",
    "        self.prediction = None  # Предсказание для узла, если он лист\n",
    "\n",
    "    def fit(self, X, y, depth):\n",
    "        \"\"\"\n",
    "        Обучает дерево регрессии.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Входные признаки.\n",
    "            y (np.ndarray): Целевая переменная (остатки в контексте GB).\n",
    "            depth (int): Текущая глубина дерева.\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Если достигнута максимальная глубина или недостаточно примеров, делаем узел листом\n",
    "        if depth >= self.max_depth or n_samples < 2:\n",
    "            self.is_leaf = True\n",
    "            self.prediction = np.mean(y) if n_samples > 0 else 0.0\n",
    "            return\n",
    "\n",
    "        # Находим лучшее разделение (признак и порог)\n",
    "        best_split = self._find_best_split(X, y)\n",
    "\n",
    "        if best_split is None:\n",
    "             # Не удалось найти хорошее разделение, делаем узел листом\n",
    "             self.is_leaf = True\n",
    "             self.prediction = np.mean(y) if n_samples > 0 else 0.0\n",
    "             return\n",
    "\n",
    "        self.is_leaf = False\n",
    "        self.feature_index = best_split['feature_index']\n",
    "        self.threshold = best_split['threshold']\n",
    "\n",
    "        # Разделяем данные\n",
    "        left_indices = X[:, self.feature_index] <= self.threshold\n",
    "        right_indices = ~left_indices # Инвертируем булевы индексы\n",
    "\n",
    "        X_left, y_left = X[left_indices], y[left_indices]\n",
    "        X_right, y_right = X[right_indices], y[right_indices]\n",
    "\n",
    "        # Рекурсивно строим поддеревья\n",
    "        self.left_tree = SimpleRegressionTree(max_depth=self.max_depth)\n",
    "        self.left_tree.fit(X_left, y_left, depth + 1)\n",
    "\n",
    "        self.right_tree = SimpleRegressionTree(max_depth=self.max_depth)\n",
    "        self.right_tree.fit(X_right, y_right, depth + 1)\n",
    "\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Находит лучшее разделение (признак и порог), минимизирующее MSE.\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        best_mse = float('inf')\n",
    "        best_split = None\n",
    "\n",
    "        # Перебираем все признаки\n",
    "        for feature_index in range(n_features):\n",
    "            feature_values = X[:, feature_index]\n",
    "            unique_values = np.unique(feature_values)\n",
    "\n",
    "            # Перебираем потенциальные пороги\n",
    "            thresholds = (unique_values[:-1] + unique_values[1:]) / 2 if len(unique_values) > 1 else unique_values\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                # Разделяем данные по текущему порогу\n",
    "                left_indices = feature_values <= threshold\n",
    "                right_indices = ~left_indices\n",
    "\n",
    "                y_left, y_right = y[left_indices], y[right_indices]\n",
    "\n",
    "                # Вычисляем MSE для текущего разделения\n",
    "                # MSE = sum((y_i - mean_left)^2) + sum((y_j - mean_right)^2)\n",
    "                mse = 0.0\n",
    "                if len(y_left) > 0:\n",
    "                    mean_left = np.mean(y_left)\n",
    "                    mse += np.sum((y_left - mean_left)**2)\n",
    "                if len(y_right) > 0:\n",
    "                    mean_right = np.mean(y_right)\n",
    "                    mse += np.sum((y_right - mean_right)**2)\n",
    "\n",
    "                # Если текущее MSE меньше лучшего, обновляем\n",
    "                if mse < best_mse:\n",
    "                    best_mse = mse\n",
    "                    best_split = {\n",
    "                        'feature_index': feature_index,\n",
    "                        'threshold': threshold\n",
    "                    }\n",
    "\n",
    "        return best_split\n",
    "\n",
    "\n",
    "    def predict_single(self, x):\n",
    "        \"\"\"\n",
    "        Прогнозирует значение для одного примера.\n",
    "        \"\"\"\n",
    "        if self.is_leaf:\n",
    "            return self.prediction\n",
    "\n",
    "        if x[self.feature_index] <= self.threshold:\n",
    "            if self.left_tree is not None:\n",
    "                 return self.left_tree.predict_single(x)\n",
    "            else:\n",
    "                 # Этого не должно происходить при правильной постройке дерева\n",
    "                 return self.prediction # Возвращаем предсказание родительского узла\n",
    "        else:\n",
    "            if self.right_tree is not None:\n",
    "                 return self.right_tree.predict_single(x)\n",
    "            else:\n",
    "                 # Этого не должно происходить при правильной постройке дерева\n",
    "                 return self.prediction # Возвращаем предсказание родительского узла\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Прогнозирует значения для массива примеров.\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        n_samples = X.shape[0]\n",
    "        predictions = np.zeros(n_samples)\n",
    "        for i in range(n_samples):\n",
    "            predictions[i] = self.predict_single(X[i])\n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Реализация алгоритма Gradient Boosting Regressor\n",
    "class SimpleGradientBoostingRegressor:\n",
    "    \"\"\"\n",
    "    Простая реализация Gradient Boosting Regressor\n",
    "    с использованием простых деревьев регрессии в качестве базовых учеников.\n",
    "    Использует только numpy и pandas.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        \"\"\"\n",
    "        Инициализация Gradient Boosting Regressor.\n",
    "\n",
    "        Args:\n",
    "            n_estimators (int): Количество базовых учеников (деревьев). По умолчанию 100.\n",
    "            learning_rate (float): Скорость обучения (шаг градиентного спуска). По умолчанию 0.1.\n",
    "            max_depth (int): Максимальная глубина базовых деревьев. По умолчанию 3.\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.estimators = [] # Список базовых учеников (SimpleRegressionTree)\n",
    "        self.initial_prediction = None # Начальное предсказание (среднее значение y)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучает модель Gradient Boosting.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray или pd.DataFrame): Входные признаки.\n",
    "            y (np.ndarray или pd.Series): Целевая переменная.\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # Шаг 1: Инициализируем модель константой (средним значением y)\n",
    "        self.initial_prediction = np.mean(y)\n",
    "        # Инициализируем текущие предсказания\n",
    "        current_predictions = np.full(n_samples, self.initial_prediction)\n",
    "\n",
    "        self.estimators = []\n",
    "\n",
    "        # Основной цикл Gradient Boosting\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Шаг 2: Вычисляем \"отрицательные градиенты\" (остатки)\n",
    "            # Для MSE функции потерь, отрицательный градиент = (y - current_prediction)\n",
    "            residuals = y - current_predictions\n",
    "\n",
    "            # Шаг 3: Обучаем новое базовое дерево на остатках\n",
    "            tree = SimpleRegressionTree(max_depth=self.max_depth)\n",
    "            tree.fit(X, residuals, depth=0)\n",
    "\n",
    "            # Шаг 4: Предсказываем остатки с помощью нового дерева\n",
    "            tree_predictions = tree.predict(X)\n",
    "\n",
    "            # Шаг 5: Обновляем текущие предсказания с учетом скорости обучения\n",
    "            current_predictions += self.learning_rate * tree_predictions\n",
    "\n",
    "            # Сохраняем обученное дерево\n",
    "            self.estimators.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Прогнозирует значения для входных данных.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray или pd.DataFrame): Входные данные.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Спрогнозированные значения.\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # Начинаем с начального предсказания\n",
    "        predictions = np.full(n_samples, self.initial_prediction)\n",
    "\n",
    "        # Добавляем предсказания от каждого базового дерева с учетом скорости обучения\n",
    "        for tree in self.estimators:\n",
    "            predictions += self.learning_rate * tree.predict(X)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "# 2. Симуляция данных для тестирования Gradient Boosting Regressor\n",
    "\n",
    "# Генерируем данные с нелинейной зависимостью и шумом\n",
    "np.random.seed(42)\n",
    "n_samples_sim = 200\n",
    "X_sim = np.random.rand(n_samples_sim, 2) * 10 # Признаки от 0 до 10\n",
    "# Целевая переменная: нелинейная функция признаков + шум\n",
    "y_sim = 2 * X_sim[:, 0]**2 - 3 * X_sim[:, 1] + np.sin(X_sim[:, 0] * X_sim[:, 1]) + np.random.normal(0, 5, n_samples_sim)\n",
    "\n",
    "\n",
    "# 3. Тестирование и сравнение\n",
    "\n",
    "# Используем нашу реализацию Gradient Boosting Regressor\n",
    "my_gbr = SimpleGradientBoostingRegressor(n_estimators=50, learning_rate=0.2, max_depth=2) # Уменьшим n_estimators для скорости\n",
    "my_gbr.fit(X_sim, y_sim)\n",
    "my_predictions = my_gbr.predict(X_sim)\n",
    "\n",
    "# Вычисляем среднеквадратичную ошибку (MSE) на обучающих данных\n",
    "my_mse = np.mean((y_sim - my_predictions)**2)\n",
    "print(f\"MSE нашей реализации Gradient Boosting Regressor на симулированных данных: {my_mse:.4f}\")\n",
    "\n",
    "# Сравнение со стандартной реализацией (sklearn)\n",
    "# Для сравнения разрешено использовать sklearn\n",
    "# try:\n",
    "#     from sklearn.ensemble import GradientBoostingRegressor\n",
    "#     from sklearn.metrics import mean_squared_error\n",
    "#\n",
    "#     # Используем GradientBoostingRegressor из sklearn\n",
    "#     # random_state для воспроизводимости\n",
    "#     sklearn_gbr = GradientBoostingRegressor(n_estimators=50, learning_rate=0.2, max_depth=2, random_state=42)\n",
    "#     sklearn_gbr.fit(X_sim, y_sim)\n",
    "#     sklearn_predictions = sklearn_gbr.predict(X_sim)\n",
    "#\n",
    "#     # Вычисляем MSE sklearn\n",
    "#     sklearn_mse = mean_squared_error(y_sim, sklearn_predictions)\n",
    "#     print(f\"MSE sklearn GradientBoostingRegressor на симулированных данных: {sklearn_mse:.4f}\")\n",
    "#\n",
    "#     # Сравнение предсказаний\n",
    "#     predictions_mse = np.mean((my_predictions - sklearn_predictions)**2)\n",
    "#     print(f\"MSE между предсказаниями нашей и sklearn реализаций: {predictions_mse:.6f}\")\n",
    "#\n",
    "# except ImportError:\n",
    "#     print(\"\\nБиблиотека sklearn не найдена. Пропуск сравнения.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"\\nОшибка при сравнении со sklearn: {e}\")\n",
    "\n",
    "# Визуализация (опционально, требует matplotlib)\n",
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# # Визуализация предсказаний vs истинных значений для одного признака (если признаков > 1, выбираем первый)\n",
    "# if X_sim.shape[1] >= 1:\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     # Сортируем по первому признаку для лучшей визуализации\n",
    "#     sort_indices = np.argsort(X_sim[:, 0])\n",
    "#     plt.scatter(X_sim[sort_indices, 0], y_sim[sort_indices], label='Истинные значения', alpha=0.6)\n",
    "#     plt.plot(X_sim[sort_indices, 0], my_predictions[sort_indices], color='red', label='Наши предсказания', linewidth=2)\n",
    "#     # if 'sklearn_predictions' in locals():\n",
    "#     #      plt.plot(X_sim[sort_indices, 0], sklearn_predictions[sort_indices], color='green', linestyle='--', label='sklearn предсказания', linewidth=2)\n",
    "#\n",
    "#     plt.title('Сравнение предсказаний Gradient Boosting Regressor')\n",
    "#     plt.xlabel('Признак 1')\n",
    "#     plt.ylabel('Целевая переменная')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
